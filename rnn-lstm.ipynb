{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd169f3a-280c-4935-9e1c-f8d8f7dc6cc1",
   "metadata": {},
   "source": [
    "# RNN text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62b8669-91ab-4001-89b7-667b57509bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db01c97-58c7-4704-b8e5-3bb942af3e1e",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2b44dc-8e74-43da-841c-8ca68b015972",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('./data/movies_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe922b0-b83d-408a-bae2-e0605029a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gonna start with a simple binary classification task using the two most common genres\n",
    "data = movies[movies['Genre'].isin(['comedy', 'drama'])].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa81bc3-b4a1-4cf0-87bd-7ab329921996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10343 entries, 1 to 20956\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Release Year      10343 non-null  int64 \n",
      " 1   Title             10343 non-null  object\n",
      " 2   Origin/Ethnicity  10343 non-null  object\n",
      " 3   Director          10343 non-null  object\n",
      " 4   Genre             10343 non-null  object\n",
      " 5   Plot              10343 non-null  object\n",
      " 6   plot_length       10343 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 646.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e80504-aaec-423a-8db2-a69046268bb0",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98d36e7-4c3b-44cf-ba8e-c31c2a409dc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "data": {
      "text/plain": [
       "drama     0.576622\n",
       "comedy    0.423378\n",
       "Name: Genre, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9322f36-17d6-4cda-8bec-1feefadaedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Plot'], data['Genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f12ec3-b456-4b54-9ff0-8b6317a0d8cf",
   "metadata": {},
   "source": [
    "## Prepare text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0205a3-d192-43ee-b9ff-b8e5dfd15264",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(1000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eadd273e-3811-4424-a1d3-38b2592bd841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc063800-d702-48c7-8b71-1fb8526f1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e8687b-b6f5-44cf-91c7-62105ca2bbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['plot_length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "441c8ef0-fc84-47f8-87d5-3eedda68b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = pad_sequences(X_train_token, maxlen = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "163e5443-b3f0-4f57-8944-c426bfa3d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq = pad_sequences(X_test_token, maxlen = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "980d3b13-3016-41e3-97f4-bff56bd04598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_token = np.where((y_train == 'drama'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8358c732-1028-4823-83e0-0e88856bf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_token = np.where((y_test == 'drama'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7ed09d-a5a2-4654-9d9a-6cc3e1f9181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208afa45-cf83-4d7e-abc4-856a5e04e67f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888fb4b6-f235-4337-855f-ed0f6531d201",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82331e74-b4ee-4a60-90f1-e49a2d1cf71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = tokenizer.num_words, output_dim = 64))\n",
    "model.add(SimpleRNN(16))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f21f8635-b279-4745-9690-28e6614a5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='bce', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "987959da-c401-482d-b91a-10a547ebd8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 51s 211ms/step - loss: 0.2651 - acc: 0.8975 - val_loss: 0.8740 - val_acc: 0.6210\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 51s 212ms/step - loss: 0.1780 - acc: 0.9318 - val_loss: 1.1480 - val_acc: 0.6500\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 49s 204ms/step - loss: 0.1230 - acc: 0.9538 - val_loss: 1.3839 - val_acc: 0.6419\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 49s 203ms/step - loss: 0.1079 - acc: 0.9624 - val_loss: 1.3265 - val_acc: 0.6350\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 49s 202ms/step - loss: 0.0621 - acc: 0.9783 - val_loss: 1.8383 - val_acc: 0.6458\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 50s 204ms/step - loss: 0.0589 - acc: 0.9813 - val_loss: 1.9567 - val_acc: 0.6199\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 49s 203ms/step - loss: 0.0635 - acc: 0.9774 - val_loss: 1.5670 - val_acc: 0.6299\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 49s 200ms/step - loss: 0.0523 - acc: 0.9801 - val_loss: 2.0381 - val_acc: 0.6384\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 50s 208ms/step - loss: 0.0534 - acc: 0.9821 - val_loss: 1.8659 - val_acc: 0.6172\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 50s 204ms/step - loss: 0.0338 - acc: 0.9887 - val_loss: 2.2886 - val_acc: 0.6152\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_seq, y_train_token, epochs = 10, validation_data=(X_test_seq, y_test_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205376e-03e6-446b-b2f2-49104d73bd29",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a543d2-fd54-4c2d-92da-755e619d48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = tokenizer.num_words, output_dim = 64))\n",
    "model2.add(LSTM(16))\n",
    "model2.add(Dense(200, activation = 'relu'))\n",
    "model2.add(Dense(200, activation = 'relu'))\n",
    "model2.add(Dense(1, activation = 'sigmoid'))\n",
    "model2.compile(loss='bce', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d06eda-0f76-4813-b918-bd3d698c8c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 17s 68ms/step - loss: 0.6720 - acc: 0.5937 - val_loss: 0.5772 - val_acc: 0.6821\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 17s 68ms/step - loss: 0.5283 - acc: 0.7491 - val_loss: 0.5761 - val_acc: 0.7258\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 17s 68ms/step - loss: 0.4834 - acc: 0.7746 - val_loss: 0.5613 - val_acc: 0.7258\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 16s 66ms/step - loss: 0.4388 - acc: 0.8085 - val_loss: 0.5643 - val_acc: 0.7231\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 16s 66ms/step - loss: 0.3996 - acc: 0.8235 - val_loss: 0.5984 - val_acc: 0.7320\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 16s 65ms/step - loss: 0.3767 - acc: 0.8317 - val_loss: 0.6605 - val_acc: 0.7162\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 16s 67ms/step - loss: 0.3596 - acc: 0.8464 - val_loss: 0.6426 - val_acc: 0.7038\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 16s 68ms/step - loss: 0.3285 - acc: 0.8608 - val_loss: 0.6698 - val_acc: 0.6253\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 17s 69ms/step - loss: 0.4330 - acc: 0.7955 - val_loss: 0.6667 - val_acc: 0.6964\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 16s 68ms/step - loss: 0.3282 - acc: 0.8624 - val_loss: 0.6832 - val_acc: 0.6961\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train_seq, y_train_token, epochs = 10, validation_data=(X_test_seq, y_test_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4e778-d88e-44ef-acfa-f1314b0e612a",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f732551f-0f94-4c02-bf2a-b5341f45a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim = tokenizer.num_words, output_dim = 64))\n",
    "model3.add(GRU(16))\n",
    "model3.add(Dense(200, activation = 'relu'))\n",
    "model3.add(Dense(200, activation = 'relu'))\n",
    "model3.add(Dense(1, activation = 'sigmoid'))\n",
    "model3.compile(loss='bce', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90975347-97a0-4379-97ce-e6236fe75252",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 199s 817ms/step - loss: 0.6768 - acc: 0.5714 - val_loss: 0.6544 - val_acc: 0.6516\n",
      "Epoch 2/10\n",
      "  6/243 [..............................] - ETA: 3:10 - loss: 0.6622 - acc: 0.6447"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ade4cd120aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train_seq, y_train_token, epochs = 10, validation_data=(X_test_seq, y_test_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d525c06-9d19-4496-b15d-81c461fd200f",
   "metadata": {},
   "source": [
    "## Gonna optimize my LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a3c6531-b1d6-467f-929e-49eae775bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq2 = pad_sequences(X_train_token, maxlen = data['plot_length'].max())\n",
    "X_test_seq2 = pad_sequences(X_test_token, maxlen = data['plot_length'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8338463e-8708-4b1e-9475-86a5c2bf0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22c42966-bea3-4a0d-9681-cbc917cf9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Embedding(input_dim = tokenizer.num_words, output_dim = 64))\n",
    "model4.add(LSTM(16))\n",
    "model4.add(Dense(200, activation = 'relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(200, activation = 'relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(1, activation = 'sigmoid'))\n",
    "model4.compile(loss='bce', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70e9026c-4781-45b3-b4eb-b20b25f2e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 49s 201ms/step - loss: 0.6670 - acc: 0.6013 - val_loss: 0.6714 - val_acc: 0.6160\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 48s 200ms/step - loss: 0.5245 - acc: 0.7481 - val_loss: 0.7063 - val_acc: 0.5882\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 49s 202ms/step - loss: 0.4853 - acc: 0.7800 - val_loss: 0.7003 - val_acc: 0.6222\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 48s 198ms/step - loss: 0.4523 - acc: 0.7907 - val_loss: 0.8374 - val_acc: 0.6179\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 49s 201ms/step - loss: 0.4137 - acc: 0.8137 - val_loss: 0.7638 - val_acc: 0.5994\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 48s 199ms/step - loss: 0.4520 - acc: 0.8020 - val_loss: 0.9622 - val_acc: 0.5916\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 49s 202ms/step - loss: 0.3861 - acc: 0.8381 - val_loss: 1.0345 - val_acc: 0.6009\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 48s 199ms/step - loss: 0.3701 - acc: 0.8408 - val_loss: 1.0701 - val_acc: 0.5824\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 48s 200ms/step - loss: 0.3340 - acc: 0.8570 - val_loss: 1.1205 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 48s 199ms/step - loss: 0.2944 - acc: 0.8718 - val_loss: 1.1176 - val_acc: 0.6241\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train_seq2, y_train_token, epochs = 10, validation_data=(X_test_seq2, y_test_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561583c-584f-44ca-b272-b98cdd100aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
